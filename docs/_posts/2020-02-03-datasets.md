---
title: "Datasets - Data types"
excerpt: "The different types of data used for research in this thesis."

sidebar:
  nav: "docs"

classes: wide

categories:
- previous work

tags:
- logbook
- studying
- training

author: NuriaOF
pinned: false


---

We will handle data of different nature that increase the degree of difficulty. The code to generate these samples can be found [here](https://github.com/RoboticsURJC-students/2017-tfm-nuria-oyaga/tree/master/Generator)

## Linear Functions dataset
It is the simplest data to handle. The input of the network is a sequence of 20 numbers that follow the function of a line and the value that the network will return to us is the corresponding value of the function at point 20 + gap.
The samples are stored in a .txt file in which each line corresponds to a sample and the values of the function are stored in points [0,19] and 19 + gap.
In the following figure you can see an example of a sample of this type of functions:

{% include figure image_path="/assets/images/logbook/media/linear_function_sample.png" alt="Linear function sample" %}

To reduce complexity and avoid infinite slope lines, samples have been generated with a limitation in their slope defined in the configuration file.

## URM Vectors dataset
We increase the complexity of the previous data by increasing a dimension. We have created several 1D images in which the position of an object is represented at each moment of time. Each sample consists of 20 + 1 vectors, so that each vector consists of 320 positions and only activates (has a value of 255) that corresponds to the position in which the object would be found. To calculate the position we use a URM movement formula.
In the following figure you can see an example of a sample of this type of samples:

{% include figure image_path="/assets/images/logbook/media/vector_sample.png" alt="Vector sample" %}

The 2D image represents in each row a continuous moment of time with the exception of the last row that corresponds to the position to be predicted with a gap of 10. In addition, the speed of the object is limited so that in the prediction the object is always in the image.

## URM Point Frames dataset
The next step to increase the complexity is to increase one more dimension. In this way, each sample will consist of 20 + 1 images (frames) in which the URM movement of an object will be represented through the time that is represented with a single pixel.
In the following video you can see an example of a sample of this type of samples:

{% include video id="RCEWNrTaYi8" provider="youtube" %}

As in the previous case, the speed of the object is limited so that in the prediction the object is always in the image.

### Linear motion
For this motion type the function is:

```ruby
  g = lambda y, m: (m * y) + y0
```

And in the next you can see a sample of this:

{% include video id="6M4slvtwdr0" provider="youtube" %}


