---
title: "Week 5 - Training nets with a big dataset"
excerpt: "It is evaluated how a large increase in the number of samples affects the efficiency of the networks."
sidebar:
  nav: "docs"

classes: wide

categories:
- logbook

tags:
- logbook
- studying

author: NuriaOF
pinned: false


---

## Meeting summary
- The main objective of the previous two weeks was to adapt the code to be able to train networks with larger datasets in order to analyze the effect that the considerable increase in the number of samples has on efficiency. This objective has been achieved, which allows us to advance in the established roadmap.
- Consequently with the previous point, this week I will carry out the necessary training and tests to see the effect of the increase in the number of samples.
- The objective of refactoring the code for modeled samples has not yet been attacked, so it will be a pending task the next few weeks.

## To Do
The tasks proposed for this week are

- [X] Train networks with more samples (100000) in linear movement dataset with 3 degrees of freedom.
..- [X] Train Non-Recurrent networks.
..- [X] Train LSTM networks.
..- [X] Train ConvLSTM networks.
- [ ] Refactor the code to be able to train and evaluate the networks with modeled data.

## Non-Recurrent Network

I used the same structure that in the previous training:
{% include figure image_path="/assets/images/logbook/week5/NoRec/15_False_relu_categorical_crossentropy_10_properties.png" alt="Non recurrent network structure" %}
{% include figure image_path="/assets/images/logbook/week5/NoRec/15_False_relu_categorical_crossentropy_10_history.png" alt="Loss history" %}
In the next picture you can see a summary of the error committed
{% include figure image_path="/assets/images/logbook/week5/NoRec/error_stats.png" alt="Error stats" %}


## LSTM Network

I used the same structure that in the previous training:
{% include figure image_path="/assets/images/logbook/week5/LSTM/15_False_relu_categorical_crossentropy_10_properties.png" alt="LSTM network structure" %}
{% include figure image_path="/assets/images/logbook/week5/LSTM/15_False_relu_categorical_crossentropy_10_history.png" alt="Loss history" %}
In the next picture you can see a summary of the error committed
{% include figure image_path="/assets/images/logbook/week5/LSTM/error_stats.png" alt="Error stats" %}

## ConvLSTM Network

I used the same structure that in the previous training:
{% include figure image_path="/assets/images/logbook/week5/ConvLSTM/15_False_relu_categorical_crossentropy_10_properties.png" alt="ConvLSTM network structure" %}
{% include figure image_path="/assets/images/logbook/week5/ConvLSTM/15_False_relu_categorical_crossentropy_10_history.png" alt="Loss history" %}
In the next picture you can see a summary of the error committed
{% include figure image_path="/assets/images/logbook/week5/ConvLSTM/error_stats.png" alt="Error stats" %}
